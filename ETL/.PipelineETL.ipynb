{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3uOpZ1sop4GX"
   },
   "source": [
    "# Pipeline ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHiYyb75sMLP"
   },
   "source": [
    "## Extração\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ryxXdj_uqGzX"
   },
   "source": [
    "Em ETL/extração.py, os dados são extraídos dos arquivos .CSV da prefeitura que estão na pasta data/\n",
    "\n",
    "Utilizando a bibilioteca Pandas, criamos um dataframe para cada arquivo entre 2006 e 2017, armazenamos todos em uma lista e depois os concatenamos e salvamos em um único grande arquivo .csv que será transformado posteriormente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aDlkFrGPnmLA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "pasta = Path(r\"data\")\n",
    "\n",
    "# Usa glob() do objeto Path de pathlib para conseguir o path para todos os arquivos CSV entre 2006 e 2017\n",
    "arquivos_csv = sorted(\n",
    "    [arq for arq in pasta.glob(\"recife-dados-despesas-*.csv\") \n",
    "     if \"2006\" <= arq.stem.split('-')[-1] <= \"2017\"]\n",
    ") \n",
    "\n",
    "lista_dfs = []\n",
    "\n",
    "# Tabelas são carregads como dataframes e armazenadas na lista\n",
    "for arq in arquivos_csv:\n",
    "    data_frame = pd.read_csv(arq, sep=';', encoding='utf-8') \n",
    "    lista_dfs.append(data_frame)\n",
    "\n",
    "# Concatenação das tabelas na lista\n",
    "df_final = pd.concat(lista_dfs) \n",
    "\n",
    "# Salva dataframe unificado para transformação\n",
    "df_final.to_csv(\"despesas_recife.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWXbD_A9s6jy"
   },
   "source": [
    "## Transformação\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6y22qSCtEp0"
   },
   "source": [
    "Em ETL/transformação.py os dados são transformados, garantindo consistência dos dados antes destes serem carregados no banco de dados Postgres.\n",
    "\n",
    "Primeiramente carregamos o CSV unificado criado no primeiro passo e indentificamos as colunas cujos elementos devem ser valores inteiros(Colunas relacionados a anos, meses e códigos de identificação) e aquelas colunas cujos valores devem ser números decimais (Valores monetários)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dmm2mk3zuaxd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carrega dataframe unificado\n",
    "df = pd.read_csv(\"despesas_recife.csv\", encoding='utf-8')\n",
    "\n",
    "\n",
    "# Teste se existia alguma valor faltando em alguma coluna da tabela --- resultado 0 valores faltando nas colunas\n",
    "# assim não foi preciso tratar valores faltantes\n",
    "# print(df.isnull().sum())\n",
    "\n",
    "\n",
    "COL_INT = ('empenho_ano', 'ano_movimentacao', 'mes_movimentacao', 'orgao_codigo',\n",
    "            'grupo_despesa_codigo','modalidade_aplicacao_codigo','elemento_codigo',\n",
    "            'subelemento_codigo','funcao_codigo','subfuncao_codigo','programa_codigo',\n",
    "            'acao_codigo','fonte_recurso_codigo','empenho_numero','subempenho', 'credor_codigo',\n",
    "            'modalidade_licitacao_codigo')\n",
    "\n",
    "# Opta-se por numeric ao invés de float para evitar problemas com arredondamento e conseguir mais precisão\n",
    "COL_NUMERIC = ('valor_empenhado', 'valor_liquidado', 'valor_pago')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7EYCkvFkvZQL"
   },
   "source": [
    "Em seguida, efetuamos as transformações. Removemos espaços vazios e tornamos todos os caracteres de todas as colunas minúsculos para garantir que não haja uma repetição errônea de dados (Exemplo: Várias entradas para o mesmo Orgão só porque algumas dessas entradas têm uma quantidade diferente de espaços brancos.)\n",
    "\n",
    "Então, convertemos as colunas previamente identificadas para int e numeric. No caso de numeric, como descobrimos uma inconsistência em como os valores monetários são armazenadas na tabela (Pré-2016: separação de decimais com . Pós-2016: separação de decimais com ,) primeiro trocamos ',' por '.' nas colunas de dinheiro pós-2016 e só então convertemos para numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mZmyhDsqv5-O"
   },
   "outputs": [],
   "source": [
    "# Padronização das colunas\n",
    "df.columns = (\n",
    "    df.columns\n",
    "    .str.strip()         # Remove espaços vazios no começo e fim\n",
    "    .str.lower()         # Deixa tudo minúsculo\n",
    "    .str.replace(\" \", \"_\")  # Substitui espaços por underline\n",
    ")\n",
    "\n",
    "for coluna in COL_INT:\n",
    "    df[coluna] = df[coluna].astype(int)\n",
    "\n",
    "# Erro na transformação, a partir de 2016 'valor_empenhado', 'valor_liquidado', 'valor_pago' começaram a vir\n",
    "# com , e não com . como nos anos anteriores\n",
    "for coluna in COL_NUMERIC:\n",
    "    # Para os anos a partir de 2016, troca vírgula por ponto antes de converter\n",
    "    mask_2016 = df['ano_movimentacao'] >= 2016\n",
    "    df.loc[mask_2016, coluna] = (\n",
    "        df.loc[mask_2016, coluna]\n",
    "        .astype(str)\n",
    "        .str.replace('.', '', regex=False)   # Remove separador de milhar, se existir\n",
    "        .str.replace(',', '.', regex=False)\n",
    "    )\n",
    "\n",
    "    # Aqui converte para numeric e errors='coerce' faz valores inválidos virarem NAN por precaução\n",
    "    df[coluna] = pd.to_numeric(df[coluna],errors='coerce')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xy-8UsZwCrF"
   },
   "source": [
    "Por fim, asseguramos que todas as demais colunas sejam string e armazenamos o dateframe transformado em outro arquivo csv para o carregamento no banco de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O2E-js66wEEt"
   },
   "outputs": [],
   "source": [
    "# Pega o conjunto de todas as colunas\n",
    "todas_colunas = set(df.columns)\n",
    "\n",
    "# Subtrai as colunas numéricas e inteiras\n",
    "colunas_string = todas_colunas - set(COL_INT) - set(COL_NUMERIC)\n",
    "\n",
    "# Converte as colunas restantes para string\n",
    "for coluna in colunas_string:\n",
    "    df[coluna] = df[coluna].astype(str)\n",
    "\n",
    "\n",
    "# Salvando tratamento em um novo arquivo csv\n",
    "df.to_csv(\"despesas_recife_tratadas.csv\", index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krLqRJatyj3P"
   },
   "source": [
    "## Carregamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24o2OwyQzXuw"
   },
   "source": [
    "Inicialmente configuramos a conexão com o banco de dados postgres utilizando SQLAlchemy e váriaveis definidas no arquivo .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvRRQ5Rlzs-w"
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "DATABASE_URL = f\"postgresql+psycopg2://{os.getenv('DATABASE_USER')}:{os.getenv('DATABASE_PASSWORD')}@{os.getenv('DATABASE_HOST')}:{os.getenv('DATABASE_PORT')}/{os.getenv('DATABASE_NAME')}\"\n",
    "engine = create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-Y1Kq7Lyo7g"
   },
   "source": [
    "Em ETL/carregamento.py realizamos o carregamento dos dados tratados para o postgres. Primeiramente definimos o tipo que cada coluna deve ter no banco de dados e então utilizamos o método .to_sql da biblioteca pandas em conjunta com a conexão ao banco de dados Postgres feita com SQLAlchemy para realizar o upload da tabela transformada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A3-IxAqWyooR"
   },
   "outputs": [],
   "source": [
    "from postgres.engine import engine\n",
    "from sqlalchemy.types import Integer, Numeric, String\n",
    "import pandas as pd\n",
    "\n",
    "# Carrega o CSV JÁ TRATADO\n",
    "df = pd.read_csv(\"despesas_recife_tratadas.csv\", encoding='utf-8')\n",
    "\n",
    "# Apenas mapeia tipos do Pandas para o PostgreSQL evitando que ele interprete sozinho e converta os valores que eu já havia transformado\n",
    "tipos_colunas_sqlalchemy = {\n",
    "    # Colunas inteiras\n",
    "    'ano_movimentacao': Integer(),\n",
    "    'mes_movimentacao': Integer(),\n",
    "    'orgao_codigo': Integer(),\n",
    "    'grupo_despesa_codigo': Integer(),\n",
    "    'modalidade_aplicacao_codigo': Integer(),\n",
    "    'elemento_codigo': Integer(),\n",
    "    'subelemento_codigo': Integer(),\n",
    "    'funcao_codigo': Integer(),\n",
    "    'subfuncao_codigo': Integer(),\n",
    "    'programa_codigo': Integer(),\n",
    "    'acao_codigo': Integer(),\n",
    "    'fonte_recurso_codigo': Integer(),\n",
    "    'empenho_ano': Integer(),\n",
    "    'empenho_numero': Integer(),\n",
    "    'subempenho': Integer(),\n",
    "    'credor_codigo': Integer(),\n",
    "    'modalidade_licitacao_codigo': Integer(),\n",
    "\n",
    "    # Colunas numéricas\n",
    "    'valor_empenhado': Numeric(18, 2),\n",
    "    'valor_liquidado': Numeric(18, 2),\n",
    "    'valor_pago': Numeric(18, 2),\n",
    "\n",
    "    #  colunas que são strings\n",
    "    'orgao_nome': String(255),\n",
    "    'unidade_codigo': String(50),  # Códigos não numéricos são strings\n",
    "    'unidade_nome': String(255),\n",
    "    'categoria_economica_codigo': String(50),\n",
    "    'categoria_economica_nome': String(255),\n",
    "    'grupo_despesa_nome': String(255),\n",
    "    'modalidade_aplicacao_nome': String(255),\n",
    "    'elemento_nome': String(255),\n",
    "    'subelemento_nome': String(255),\n",
    "    'funcao_nome': String(255),\n",
    "    'subfuncao_nome': String(255),\n",
    "    'programa_nome': String(255),\n",
    "    'acao_nome': String(255),\n",
    "    'fonte_recurso_nome': String(255),\n",
    "    'empenho_modalidade_nome': String(255),\n",
    "    'empenho_modalidade_codigo': String(50),\n",
    "    'indicador_subempenho': String(50),\n",
    "    'credor_nome': String(255),\n",
    "    'modalidade_licitacao_nome': String(255)\n",
    "}\n",
    "\n",
    "# Envia ao banco (os dados já estão tratados)\n",
    "print(\"Carregamento de dados iniciado\")\n",
    "df.to_sql(\n",
    "    name=\"despesas_recife\",\n",
    "    con=engine,\n",
    "    if_exists=\"replace\",\n",
    "    index=False,\n",
    "    dtype=tipos_colunas_sqlalchemy\n",
    ")\n",
    "\n",
    "print(\"Carregamento de dados finalizado\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
